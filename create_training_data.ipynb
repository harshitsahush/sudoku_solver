{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to accurately train model\n",
    "#i'll simply extract digits from sample sudoku images from web\n",
    "#augment and use them to train you cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./.venv/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.21.2 in ./.venv/lib/python3.10/site-packages (from opencv-python) (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorflow==2.15 in ./.venv/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (4.25.4)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (70.1.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (0.37.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (1.65.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in ./.venv/lib/python3.10/site-packages (from tensorflow==2.15) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.32.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (1.2.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./.venv/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2024.7.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./.venv/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: imutils in ./.venv/lib/python3.10/site-packages (0.5.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n",
    "!pip install tensorflow==2.15\n",
    "!pip install imutils\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import imutils\n",
    "import imutils.perspective\n",
    "from skimage.segmentation import clear_border\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(633, 633)\n",
      "(112, 5)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 69\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m row:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# apply automatic thresholding to the cell and then clear any\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# connected borders that touch the border of the cell\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     thresh \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(cell, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m,\n\u001b[1;32m     68\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY_INV \u001b[38;5;241m|\u001b[39m cv2\u001b[38;5;241m.\u001b[39mTHRESH_OTSU)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 69\u001b[0m     thresh \u001b[38;5;241m=\u001b[39m \u001b[43mclear_border\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# find contours in the thresholded cell\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     cnts \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mfindContours(thresh\u001b[38;5;241m.\u001b[39mcopy(), cv2\u001b[38;5;241m.\u001b[39mRETR_EXTERNAL,\n\u001b[1;32m     73\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mCHAIN_APPROX_SIMPLE)\n",
      "File \u001b[0;32m~/Desktop/github_pros/sudoku_solver/.venv/lib/python3.10/site-packages/skimage/segmentation/_clear_border.py:63\u001b[0m, in \u001b[0;36mclear_border\u001b[0;34m(labels, buffer_size, bgval, mask, out)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclear_border\u001b[39m(labels, buffer_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, bgval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Clear objects connected to the label image border.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(buffer_size \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m) \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;66;03m# ignore buffer_size if mask\u001b[39;00m\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuffer size may not be greater than labels size\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for image_path in glob.glob(\"train_images/*.png\"):\n",
    "    #read image as grayscale\n",
    "\n",
    "    gray_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    #blur it slightly\n",
    "    image = gray_image\n",
    "    blurred = cv2.GaussianBlur(image, (7,7),3)\n",
    "\n",
    "    # apply adaptive thresholding and then invert the threshold map\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, \n",
    "        255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "        cv2.THRESH_BINARY, \n",
    "        11, \n",
    "        2\n",
    "    )\n",
    "    thresh = cv2.bitwise_not(thresh)\n",
    "\n",
    "    # find contours in the thresholded image and sort them by size in\n",
    "        # descending order\n",
    "    cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "        cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = imutils.grab_contours(cnts)\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    # initialize a contour that corresponds to the puzzle outline\n",
    "    puzzleCnt = None\n",
    "    # loop over the contours\n",
    "    for c in cnts:\n",
    "        # approximate the contour\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        # if our approximated contour has four points, then we can\n",
    "        # assume we have found the outline of the puzzle\n",
    "        if len(approx) == 4:\n",
    "            puzzleCnt = approx\n",
    "            break\n",
    "\n",
    "    if(len(puzzleCnt) == 0):\n",
    "        break    #no contour has been found\n",
    "    \n",
    "    # apply a four point perspective transform to both the original\n",
    "    # image and grayscale image to obtain a top-down bird's eye view\n",
    "    # of the puzzle\n",
    "\n",
    "    warped = imutils.perspective.four_point_transform(image, puzzleCnt.reshape(4, 2))\n",
    "    \n",
    "    print(warped.shape)\n",
    "\n",
    "    cells = []\n",
    "\n",
    "    h, w = warped.shape\n",
    "    cell_h, cell_w = h//9, w//9\n",
    "\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            cell = warped[i*cell_h:(i+1)*cell_h, j*cell_w:(j+1)*cell_w]        \n",
    "            cells.append(cell)\n",
    "\n",
    "\n",
    "    for row in cells:\n",
    "        for cell in row:\n",
    "            # apply automatic thresholding to the cell and then clear any\n",
    "            # connected borders that touch the border of the cell\n",
    "            thresh = cv2.threshold(cell, 0, 255,\n",
    "                cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "            thresh = clear_border(thresh)\n",
    "\n",
    "            # find contours in the thresholded cell\n",
    "            cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "                cv2.CHAIN_APPROX_SIMPLE)\n",
    "            cnts = imutils.grab_contours(cnts)\n",
    "\n",
    "\n",
    "            # if no contours were found than this is an empty cell\n",
    "            if len(cnts) == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                # otherwise, find the largest contour in the cell and create a\n",
    "                # mask for the contour\n",
    "                c = max(cnts, key=cv2.contourArea)\n",
    "                mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "                cv2.drawContours(mask, [c], -1, 255, -1)\n",
    "\n",
    "                # compute the percentage of masked pixels relative to the total\n",
    "                # area of the image\n",
    "                (h, w) = thresh.shape\n",
    "                percentFilled = cv2.countNonZero(mask) / float(w * h)\n",
    "\n",
    "                # if less than 3% of the mask is filled then we are looking at\n",
    "                # noise and can safely ignore the contour\n",
    "                if percentFilled < 0.03:\n",
    "                    pass\n",
    "\n",
    "                else:\n",
    "                    # apply the mask to the thresholded cell\n",
    "                    digit = cv2.bitwise_and(thresh, thresh, mask=mask)\n",
    "                    cv2.imwrite(f\"digits/img{i}.png\", digit)\n",
    "                    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
